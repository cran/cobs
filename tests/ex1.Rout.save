
R version 2.8.1 Patched (2009-02-23 r47990)
Copyright (C) 2009 The R Foundation for Statistical Computing
ISBN 3-900051-07-0

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> #### OOps! Running this in 'CMD check' or in *R* __for the first time__
> #### ===== gives a wrong result (at the end) than when run a 2nd time
> ####-- problem disappears with introduction of   if (psw) call ... in Fortran
> 
> suppressMessages(library(cobs))
Package SparseM (0.79) loaded.  To cite, see citation("SparseM")
> options(digits = 6)
> postscript("ex1.ps")
> 
> source(system.file("util.R", package = "cobs"))
> 
> ## Simple example from  example(cobs)
> set.seed(908)
> x <- seq(-1,1, len = 50)
> f.true <- pnorm(2*x)
> y <- f.true + rnorm(50)/10
> ## specify constraints (boundary conditions)
> con <- rbind(c( 1,min(x),0),
+              c(-1,max(x),1),
+              c( 0, 0,  0.5))
> ## obtain the median *regression* B-spline using automatically selected knots
> coR <- cobs(x,y,constraint = "increase", pointwise = con)
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...
> summaryCobs(coR)
List of 24
 $ call         : language cobs(x = x, y = y, constraint = "increase", pointwise = con)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "increase"
 $ ic           : chr "AIC"
 $ pointwise    : num [1:3, 1:3] 1 -1 0 -1 1 0 0 1 0.5
 $ select.knots : logi TRUE
 $ select.lambda: logi FALSE
 $ x            : num [1:50] -1 -0.959 -0.918 -0.878 -0.837 ...
 $ y            : num [1:50] 0.2254 0.0916 0.0803 -0.0272 -0.0454 ...
 $ resid        : num [1:50] 0.1976 0.063 0.0491 -0.0626 -0.0868 ...
 $ fitted       : num [1:50] 0.0278 0.0287 0.0312 0.0354 0.0414 ...
 $ coef         : num [1:4] 0.0278 0.0278 0.8154 1
 $ knots        : num [1:3] -1 -0.224 1
 $ k0           : num 4
 $ k            : num 4
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 6.19
 $ lambda       : num 0
 $ icyc         : int 7
 $ ifl          : int 1
 $ pp.lambda    : NULL
 $ pp.sic       : NULL
 $ i.mask       : NULL
           cb.lo        ci.lo       fit     ci.up    cb.up
1   -6.77514e-02 -0.029701622 0.0278152 0.0853320 0.123382
2   -6.41787e-02 -0.027468888 0.0280224 0.0835138 0.120224
3   -6.04433e-02 -0.024973163 0.0286442 0.0822615 0.117732
4   -5.65412e-02 -0.022212175 0.0296803 0.0815728 0.115902
5   -5.24674e-02 -0.019182756 0.0311310 0.0814447 0.114729
6   -4.82149e-02 -0.015880775 0.0329961 0.0818729 0.114207
7   -4.37751e-02 -0.012301110 0.0352757 0.0828524 0.114326
8   -3.91381e-02 -0.008437641 0.0379697 0.0843771 0.115077
9   -3.42918e-02 -0.004283290 0.0410782 0.0864397 0.116448
10  -2.92233e-02  0.000169901 0.0446012 0.0890325 0.118426
11  -2.39179e-02  0.004930665 0.0485387 0.0921467 0.120995
12  -1.83600e-02  0.010008360 0.0528906 0.0957728 0.124141
13  -1.25335e-02  0.015412811 0.0576570 0.0999012 0.127847
14  -6.42140e-03  0.021154129 0.0628378 0.1045216 0.132097
15  -6.81378e-06  0.027242531 0.0684332 0.1096238 0.136873
16   6.72715e-03  0.033688168 0.0744430 0.1151978 0.142159
17   1.37970e-02  0.040500961 0.0808672 0.1212335 0.147938
18   2.12185e-02  0.047690461 0.0877060 0.1277215 0.154193
19   2.90068e-02  0.055265726 0.0949592 0.1346527 0.160912
20   3.71760e-02  0.063235225 0.1026269 0.1420185 0.168078
21   4.57390e-02  0.071606758 0.1107090 0.1498113 0.175679
22   5.47075e-02  0.080387396 0.1192056 0.1580238 0.183704
23   6.40921e-02  0.089583438 0.1281167 0.1666500 0.192141
24   7.39018e-02  0.099200377 0.1374422 0.1756841 0.200983
25   8.41444e-02  0.109242876 0.1471823 0.1851216 0.210220
26   9.48262e-02  0.119714746 0.1573367 0.1949588 0.219847
27   1.05952e-01  0.130618921 0.1679057 0.2051925 0.229859
28   1.17526e-01  0.141957438 0.1788891 0.2158208 0.240253
29   1.29548e-01  0.153731401 0.1902870 0.2268426 0.251026
30   1.42021e-01  0.165940947 0.2020994 0.2382578 0.262178
31   1.54941e-01  0.178585191 0.2143262 0.2500672 0.273711
32   1.68306e-01  0.191662165 0.2269675 0.2622729 0.285629
33   1.82111e-01  0.205168744 0.2400233 0.2748778 0.297936
34   1.96348e-01  0.219100556 0.2534935 0.2878865 0.310639
35   2.11008e-01  0.233451886 0.2673782 0.3013046 0.323748
36   2.26079e-01  0.248215565 0.2816774 0.3151392 0.337276
37   2.41547e-01  0.263382876 0.2963910 0.3293992 0.351235
38   2.57393e-01  0.278943451 0.3115191 0.3440948 0.365645
39   2.73599e-01  0.294885220 0.3270617 0.3592382 0.380524
40   2.90023e-01  0.311080514 0.3429107 0.3747410 0.395798
41   3.06194e-01  0.327075735 0.3586411 0.3902065 0.411088
42   3.22074e-01  0.342831649 0.3742095 0.4055873 0.426345
43   3.37676e-01  0.358355597 0.3896158 0.4208761 0.441556
44   3.53012e-01  0.373655096 0.4048602 0.4360653 0.456709
45   3.68094e-01  0.388737688 0.4199426 0.4511475 0.471791
46   3.82936e-01  0.403610792 0.4348630 0.4661151 0.486790
47   3.97549e-01  0.418281590 0.4496214 0.4809611 0.501694
48   4.11944e-01  0.432756923 0.4642177 0.4956786 0.516491
49   4.26133e-01  0.447043216 0.4786521 0.5102611 0.531172
50   4.40124e-01  0.461146429 0.4929245 0.5247027 0.545725
51   4.53927e-01  0.475072016 0.5070350 0.5389979 0.560143
52   4.67551e-01  0.488824911 0.5209834 0.5531418 0.574416
53   4.81002e-01  0.502409521 0.5347698 0.5671300 0.588538
54   4.94287e-01  0.515829730 0.5483942 0.5809587 0.602501
55   5.07412e-01  0.529088909 0.5618566 0.5946243 0.616302
56   5.20381e-01  0.542189933 0.5751571 0.6081242 0.629933
57   5.33198e-01  0.555135196 0.5882955 0.6214558 0.643393
58   5.45867e-01  0.567926630 0.6012719 0.6346172 0.656677
59   5.58390e-01  0.580565721 0.6140864 0.6476070 0.669782
60   5.70769e-01  0.593053527 0.6267388 0.6604241 0.682708
61   5.83005e-01  0.605390690 0.6392293 0.6730679 0.695454
62   5.95098e-01  0.617577451 0.6515577 0.6855380 0.708017
63   6.07048e-01  0.629613656 0.6637242 0.6978347 0.720400
64   6.18854e-01  0.641498766 0.6757287 0.7099586 0.732603
65   6.30515e-01  0.653231865 0.6875711 0.7219104 0.744627
66   6.42028e-01  0.664811658 0.6992516 0.7336916 0.756475
67   6.53391e-01  0.676236478 0.7107701 0.7453037 0.768149
68   6.64600e-01  0.687504287 0.7221266 0.7567489 0.779653
69   6.75652e-01  0.698612675 0.7333211 0.7680295 0.790991
70   6.86541e-01  0.709558867 0.7443536 0.7791483 0.802166
71   6.97262e-01  0.720339721 0.7552241 0.7901084 0.813186
72   7.07810e-01  0.730951740 0.7659326 0.8009134 0.824055
73   7.18179e-01  0.741391078 0.7764791 0.8115671 0.834779
74   7.28361e-01  0.751653555 0.7868636 0.8220736 0.845367
75   7.38348e-01  0.761734678 0.7970861 0.8324375 0.855824
76   7.48134e-01  0.771629669 0.8071466 0.8426636 0.866160
77   7.57709e-01  0.781333498 0.8170452 0.8527568 0.876382
78   7.67065e-01  0.790840929 0.8267817 0.8627224 0.886499
79   7.76192e-01  0.800146569 0.8363562 0.8725659 0.896520
80   7.85083e-01  0.809244928 0.8457688 0.8822926 0.906455
81   7.93727e-01  0.818130488 0.8550193 0.8919081 0.916312
82   8.02116e-01  0.826797774 0.8641079 0.9014179 0.926100
83   8.10240e-01  0.835241429 0.8730344 0.9108274 0.935829
84   8.18091e-01  0.843456291 0.8817990 0.9201417 0.945507
85   8.25661e-01  0.851437463 0.8904015 0.9293656 0.955142
86   8.32942e-01  0.859180385 0.8988421 0.9385038 0.964742
87   8.39928e-01  0.866680887 0.9071207 0.9475605 0.974313
88   8.46612e-01  0.873935236 0.9152373 0.9565393 0.983862
89   8.52989e-01  0.880940170 0.9231918 0.9654435 0.993395
90   8.59054e-01  0.887692913 0.9309844 0.9742760 1.002915
91   8.64803e-01  0.894191180 0.9386150 0.9830389 1.012427
92   8.70233e-01  0.900433167 0.9460836 0.9917341 1.021934
93   8.75343e-01  0.906417527 0.9533902 1.0003629 1.031437
94   8.80130e-01  0.912143340 0.9605348 1.0089263 1.040939
95   8.84594e-01  0.917610075 0.9675174 1.0174248 1.050441
96   8.88735e-01  0.922817542 0.9743381 1.0258586 1.059942
97   8.92551e-01  0.927765853 0.9809967 1.0342275 1.069442
98   8.96045e-01  0.932455371 0.9874933 1.0425312 1.078941
99   8.99218e-01  0.936886669 0.9938279 1.0507692 1.088438
100  9.02069e-01  0.941060487 1.0000006 1.0589406 1.097932
knots :
[1] -1.00000 -0.22449  1.00000
coef  :
[1] 0.0278152 0.0278152 0.8153868 1.0000006
> coR1 <- cobs(x,y,constraint = "increase", pointwise = con, degree = 1)
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...
> summary(coR1)
COBS regression spline (degree = 1) from call:
	 cobs(x = x, y = y, constraint = "increase", degree = 1, pointwise = con)
{tau=0.5}-quantile;  dimensionality of fit: 4 from {4}
x$knots[1:4]: -1.000002, -0.632653,  0.183673,  1.000002
with 3 pointwise constraints
coef[1:4]: 0.0504467, 0.0504467, 0.6305155, 1.0000009
R^2 = 93.83% ;  empirical tau (over all): 21/50 = 0.42 (target tau= 0.5)
> 
> ## compute the median *smoothing* B-spline using automatically chosen lambda
> coS <- cobs(x,y,constraint = "increase", pointwise = con,
+             lambda = -1, trace = 3)

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.
loo.design2(): ->  Xeq   51 x 22 (nz = 151 =^=  0.13%) 
                  Xieq   62 x 22 (nz = 224 =^=  0.16%) 
........................ 

   The algorithm has converged.  You might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you have found the global minimum of the information criterion
   so that you can determine if you need to adjust any or all of
   'lambda.lo', 'lambda.hi' and 'lambda.length' and refit the model.

> with(coS, cbind(pp.lambda, pp.sic, k0, ifl, icyc))
        pp.lambda   pp.sic k0 ifl icyc
 [1,] 3.54019e-05 -2.64644 22   1   21
 [2,] 6.92936e-05 -2.64644 22   1   21
 [3,] 1.35631e-04 -2.64644 22   1   20
 [4,] 2.65477e-04 -2.64644 22   1   22
 [5,] 5.19629e-04 -2.64644 22   1   22
 [6,] 1.01709e-03 -2.64644 22   1   23
 [7,] 1.99080e-03 -2.68274 21   1   20
 [8,] 3.89667e-03 -2.75212 19   1   18
 [9,] 7.62711e-03 -2.73932 19   1   14
[10,] 1.49289e-02 -2.85261 16   1   13
[11,] 2.92209e-02 -2.97873 12   1   12
[12,] 5.71953e-02 -3.01058 11   1   12
[13,] 1.11951e-01 -3.04364 10   1   11
[14,] 2.19126e-01 -3.11242  8   1   12
[15,] 4.28904e-01 -3.17913  6   1   12
[16,] 8.39512e-01 -3.18824  5   1   11
[17,] 1.64321e+00 -3.01467  5   1   12
[18,] 3.21633e+00 -3.01380  4   1   11
[19,] 6.29545e+00 -3.01380  4   1   10
[20,] 1.23223e+01 -3.01380  4   1   11
[21,] 2.41190e+01 -3.01380  4   1   11
[22,] 4.72092e+01 -3.01380  4   1   10
[23,] 9.24046e+01 -3.01380  4   1   10
[24,] 1.80867e+02 -3.01380  4   1   10
[25,] 3.54019e+02 -3.01380  4   1   10
> with(coS, plot(pp.sic ~ pp.lambda, type = "b", log = "x", col=2,
+ 	       main = deparse(call)))
> ##-> very nice minimum close to 1
> 
> summaryCobs(coS)
List of 24
 $ call         : language cobs(x = x, y = y, constraint = "increase", lambda = -1, pointwise = con,      trace = 3)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "increase"
 $ ic           : NULL
 $ pointwise    : num [1:3, 1:3] 1 -1 0 -1 1 0 0 1 0.5
 $ select.knots : logi TRUE
 $ select.lambda: logi TRUE
 $ x            : num [1:50] -1 -0.959 -0.918 -0.878 -0.837 ...
 $ y            : num [1:50] 0.2254 0.0916 0.0803 -0.0272 -0.0454 ...
 $ resid        : num [1:50] 0.2254 0.0829 0.062 -0.0562 -0.0862 ...
 $ fitted       : num [1:50] 0 0.00869 0.01837 0.02906 0.04075 ...
 $ coef         : num [1:22] 0 0.00819 0.03365 0.06662 0.10458 ...
 $ knots        : num [1:20] -1 -0.918 -0.796 -0.714 -0.592 ...
 $ k0           : int [1:25] 22 22 22 22 22 22 21 19 19 16 ...
 $ k            : int 5
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 6.19
 $ lambda       : Named num 0.84
  ..- attr(*, "names")= chr "lambda"
 $ icyc         : int [1:25] 21 21 20 22 22 23 20 18 14 13 ...
 $ ifl          : int [1:25] 1 1 1 1 1 1 1 1 1 1 ...
 $ pp.lambda    : num [1:25] 0 0 0 0 0.001 0.001 0.002 0.004 0.008 0.015 ...
 $ pp.sic       : num [1:25] -2.65 -2.65 -2.65 -2.65 -2.65 ...
 $ i.mask       : logi [1:25] TRUE TRUE TRUE TRUE TRUE TRUE ...
          cb.lo       ci.lo          fit     ci.up     cb.up
1   -0.07071332 -0.03907635 -3.77249e-07 0.0390756 0.0707126
2   -0.06555125 -0.03435600  4.17438e-03 0.0427048 0.0739000
3   -0.06016465 -0.02940203  8.59400e-03 0.0465900 0.0773526
4   -0.05455349 -0.02421442  1.32585e-02 0.0507314 0.0810704
5   -0.04871809 -0.01879334  1.81678e-02 0.0551289 0.0850537
6   -0.04265897 -0.01313909  2.33220e-02 0.0597831 0.0893029
7   -0.03637554 -0.00725134  2.87210e-02 0.0646934 0.0938176
8   -0.02986704 -0.00112966  3.43649e-02 0.0698595 0.0985969
9   -0.02313305  0.00522618  4.02537e-02 0.0752812 0.1036404
10  -0.01617351  0.01181620  4.63873e-02 0.0809584 0.1089481
11  -0.00898880  0.01864020  5.27658e-02 0.0868914 0.1145204
12  -0.00157983  0.02569768  5.93891e-02 0.0930806 0.1203581
13   0.00605308  0.03298846  6.62573e-02 0.0995262 0.1264615
14   0.01391000  0.04051257  7.33704e-02 0.1062282 0.1328307
15   0.02199057  0.04826981  8.07283e-02 0.1131867 0.1394660
16   0.03029461  0.05626010  8.83310e-02 0.1204020 0.1463675
17   0.03882336  0.06448412  9.61787e-02 0.1278732 0.1535339
18   0.04757769  0.07294234  1.04271e-01 0.1355999 0.1609646
19   0.05655804  0.08163500  1.12608e-01 0.1435819 0.1686589
20   0.06576441  0.09056212  1.21191e-01 0.1518192 0.1766169
21   0.07519637  0.09972344  1.30018e-01 0.1603120 0.1848391
22   0.08485262  0.10911826  1.39090e-01 0.1690610 0.1933266
23   0.09473211  0.11874598  1.48406e-01 0.1780668 0.2020807
24   0.10483493  0.12860668  1.57968e-01 0.1873294 0.2111011
25   0.11516076  0.13870015  1.67775e-01 0.1968489 0.2203882
26   0.12570956  0.14902638  1.77826e-01 0.2066253 0.2299421
27   0.13648327  0.15958645  1.88122e-01 0.2166576 0.2397608
28   0.14748286  0.17038090  1.98663e-01 0.2269453 0.2498433
29   0.15870881  0.18140998  2.09449e-01 0.2374880 0.2601892
30   0.17016110  0.19267368  2.20480e-01 0.2482859 0.2707984
31   0.18183922  0.20417172  2.31755e-01 0.2593391 0.2816716
32   0.19374227  0.21590361  2.43276e-01 0.2706482 0.2928095
33   0.20587062  0.22786955  2.55041e-01 0.2822129 0.3042118
34   0.21822524  0.24007008  2.67051e-01 0.2940328 0.3158776
35   0.23080666  0.25250549  2.79306e-01 0.3061075 0.3278063
36   0.24361488  0.26517577  2.91806e-01 0.3184370 0.3399979
37   0.25664938  0.27808064  3.04551e-01 0.3310217 0.3524530
38   0.26990862  0.29121926  3.17541e-01 0.3438624 0.3651730
39   0.28339034  0.30459037  3.30775e-01 0.3569602 0.3781603
40   0.29709467  0.31819405  3.44255e-01 0.3703152 0.3914146
41   0.31102144  0.33203019  3.57979e-01 0.3839275 0.4049363
42   0.32517059  0.34609876  3.71948e-01 0.3977971 0.4187252
43   0.33954481  0.36040126  3.86162e-01 0.4119224 0.4327789
44   0.35414537  0.37493839  4.00621e-01 0.4263028 0.4470958
45   0.36897279  0.38971043  4.15324e-01 0.4409381 0.4616757
46   0.38402708  0.40471738  4.30273e-01 0.4558281 0.4765184
47   0.39930767  0.41995895  4.45466e-01 0.4709732 0.4916245
48   0.41479557  0.43541678  4.60887e-01 0.4863568 0.5069780
49   0.43039487  0.45099622  4.76442e-01 0.5018872 0.5224885
50   0.44609197  0.46668362  4.92117e-01 0.5175506 0.5381422
51   0.46188684  0.48247895  5.07913e-01 0.5333471 0.5539392
52   0.47773555  0.49833835  5.23786e-01 0.5492329 0.5698357
53   0.49336687  0.51398935  5.39461e-01 0.5649325 0.5855550
54   0.50873469  0.52938518  5.54891e-01 0.5803975 0.6010480
55   0.52383955  0.54452615  5.70077e-01 0.5956277 0.6163143
56   0.53868141  0.55941225  5.85018e-01 0.6106231 0.6313539
57   0.55325974  0.57404316  5.99714e-01 0.6253839 0.6461673
58   0.56757320  0.58841816  6.14165e-01 0.6399109 0.6607558
59   0.58161907  0.60253574  6.28371e-01 0.6542056 0.6751223
60   0.59539741  0.61639593  6.42332e-01 0.6682680 0.6892665
61   0.60890835  0.62999881  6.56048e-01 0.6820980 0.7031884
62   0.62215175  0.64334429  6.69520e-01 0.6956957 0.7168882
63   0.63512996  0.65643368  6.82747e-01 0.7090597 0.7303634
64   0.64784450  0.66926783  6.95729e-01 0.7221893 0.7436126
65   0.66029589  0.68184700  7.08466e-01 0.7350841 0.7566352
66   0.67248408  0.69417118  7.20958e-01 0.7477442 0.7694313
67   0.68440855  0.70624008  7.33205e-01 0.7601699 0.7820014
68   0.69606829  0.71805313  7.45207e-01 0.7723617 0.7943465
69   0.70746295  0.72961016  7.56965e-01 0.7843198 0.8064670
70   0.71859343  0.74091165  7.68478e-01 0.7960438 0.8183620
71   0.72946023  0.75195789  7.79746e-01 0.8075332 0.8300309
72   0.74006337  0.76274887  7.90769e-01 0.8187883 0.8414738
73   0.75040233  0.77328433  8.01547e-01 0.8298091 0.8526911
74   0.76047612  0.78356369  8.12080e-01 0.8405963 0.8636839
75   0.77028266  0.79358583  8.22368e-01 0.8511510 0.8744542
76   0.77982200  0.80335076  8.32412e-01 0.8614732 0.8850020
77   0.78909446  0.81285866  8.42211e-01 0.8715627 0.8953269
78   0.79809990  0.82210946  8.51765e-01 0.8814196 0.9054292
79   0.80683951  0.83110382  8.61074e-01 0.8910433 0.9153076
80   0.81531459  0.83984244  8.70138e-01 0.9004329 0.9249608
81   0.82352559  0.84832559  8.78957e-01 0.9095884 0.9343884
82   0.83147249  0.85655324  8.87531e-01 0.9185095 0.9435903
83   0.83915483  0.86452515  8.95861e-01 0.9271968 0.9525671
84   0.84657171  0.87224082  9.03946e-01 0.9356505 0.9613196
85   0.85372180  0.87969951  9.11786e-01 0.9438715 0.9698492
86   0.86060525  0.88690131  9.19381e-01 0.9518597 0.9781558
87   0.86722242  0.89384640  9.26731e-01 0.9596149 0.9862389
88   0.87357322  0.90053476  9.33836e-01 0.9671371 0.9940986
89   0.87965804  0.90696658  9.40696e-01 0.9744261 1.0017347
90   0.88547781  0.91314239  9.47312e-01 0.9814814 1.0091460
91   0.89103290  0.91906239  9.53683e-01 0.9883028 1.0163323
92   0.89632328  0.92472655  9.59808e-01 0.9948904 1.0232937
93   0.90134850  0.93013464  9.65689e-01 1.0012443 1.0300304
94   0.90610776  0.93528622  9.71326e-01 1.0073650 1.0365434
95   0.91060065  0.94018104  9.76717e-01 1.0132527 1.0428331
96   0.91482784  0.94481950  9.81863e-01 1.0189071 1.0488987
97   0.91878971  0.94920179  9.86765e-01 1.0243279 1.0547400
98   0.92248624  0.95332789  9.91422e-01 1.0295152 1.0603569
99   0.92591703  0.95719761  9.95833e-01 1.0344692 1.0657498
100  0.92908136  0.96081053  1.00000e+00 1.0391902 1.0709194
knots :
 [1] -1.0000020 -0.9183673 -0.7959184 -0.7142857 -0.5918367 -0.5102041
 [7] -0.3877551 -0.2653061 -0.1836735 -0.0612245  0.0204082  0.1428571
[13]  0.2244898  0.3469388  0.4693878  0.5510204  0.6734694  0.7551020
[19]  0.8775510  1.0000020
coef  :
 [1] -4.01161e-07  8.18714e-03  3.36534e-02  6.66159e-02  1.04576e-01
 [6]  1.50032e-01  2.00486e-01  2.70027e-01  3.35473e-01  4.05918e-01
[11]  4.83858e-01  5.64259e-01  6.37163e-01  7.05069e-01  7.77561e-01
[16]  8.30474e-01  8.78390e-01  9.18810e-01  9.54232e-01  9.87743e-01
[21]  1.00000e+00  5.99960e-01
> 
> plot(x, y, main = "cobs(x,y, constraint=\"increase\", pointwise = *)")
> matlines(x, cbind(fitted(coR), fitted(coR1), fitted(coS)),
+          col = 2:4, lty=1)
> 
> ##-- real data example (still n = 50)
> data(cars)
> attach(cars)
> co1   <- cobs(speed, dist, "increase")
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...
> co1.1 <- cobs(speed, dist, "increase", knots.add = TRUE)
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...

 Searching for missing knots ...
> co1.2 <- cobs(speed, dist, "increase", knots.add = TRUE, repeat.delete.add = TRUE)
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...

 Searching for missing knots ...
> ## These three all give the same -- only remaining knots (outermost data):
> ic <- which("call" == names(co1))
> stopifnot(all.equal(co1[-ic], co1.1[-ic]),
+           all.equal(co1[-ic], co1.2[-ic]))
> 1 - sum(co1   $ resid ^2) / sum((dist - mean(dist))^2) # R^2 = 64.2%
[1] 0.642288
> 
> co2 <- cobs(speed, dist, "increase", lambda = -1)# 6 warnings

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.
WARNING: Some lambdas had problems in rq.fit.sfnc():
      lambda icyc ifl fidel sum|res|_s  k
[1,] 2.30776   16  18 250.3     7.5999 11

   The algorithm has converged.  You might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you have found the global minimum of the information criterion
   so that you can determine if you need to adjust any or all of
   'lambda.lo', 'lambda.hi' and 'lambda.length' and refit the model.

Warning message:
In cobs(speed, dist, "increase", lambda = -1) : Check 'ifl'
> summaryCobs(co2)
List of 24
 $ call         : language cobs(x = speed, y = dist, constraint = "increase", lambda = -1)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "increase"
 $ ic           : NULL
 $ pointwise    : NULL
 $ select.knots : logi TRUE
 $ select.lambda: logi TRUE
 $ x            : num [1:50] 4 4 7 7 8 9 10 10 10 11 ...
 $ y            : num [1:50] 2 10 4 22 16 10 18 26 34 17 ...
 $ resid        : num [1:50] -4.86 3.14 -9.75 8.25 0 ...
 $ fitted       : num [1:50] 6.86 6.86 13.75 13.75 16 ...
 $ coef         : num [1:20] 6.86 10.37 14.88 17.12 19.55 ...
 $ knots        : num [1:18] 4 7 8 9 10 ...
 $ k0           : int [1:25] 16 16 16 16 16 16 15 15 14 12 ...
 $ k            : int 3
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 32539
 $ lambda       : Named num 66.3
  ..- attr(*, "names")= chr "lambda"
 $ icyc         : int [1:25] 17 17 15 16 16 16 18 16 17 19 ...
 $ ifl          : int [1:25] 1 1 1 1 1 1 1 1 1 1 ...
 $ pp.lambda    : num [1:25] 0 0.01 0.01 0.02 0.04 0.08 0.16 0.31 0.6 1.18 ...
 $ pp.sic       : num [1:25] 2.23 2.23 2.23 2.23 2.23 ...
 $ i.mask       : logi [1:25] TRUE TRUE TRUE TRUE TRUE TRUE ...
          cb.lo     ci.lo      fit   ci.up    cb.up
1   -18.0106901 -9.829675  6.86289 23.5554  31.7365
2   -15.9869426 -8.308682  7.35806 23.0248  30.7031
3   -14.7253902 -7.299595  7.85201 23.0036  30.4294
4   -14.0304376 -6.671152  8.34475 23.3607  30.7199
5   -13.6842238 -6.277147  8.83627 23.9497  31.3568
6   -13.4881973 -5.984332  9.32657 24.6375  32.1413
7   -13.2846859 -5.686895  9.81565 25.3182  32.9160
8   -12.9604500 -5.308840 10.30352 25.9159  33.5675
9   -12.4418513 -4.800750 10.79017 26.3811  34.0222
10  -11.6889866 -4.135844 11.27560 26.6871  34.2402
11  -10.6923972 -3.307777 11.75982 26.8274  34.2120
12   -9.4739641 -2.331232 12.24282 26.8169  33.9596
13   -8.0930597 -1.246053 12.72460 26.6952  33.5422
14   -6.6587120 -0.125409 13.20516 26.5357  33.0690
15   -5.3461743  0.913089 13.68450 26.4559  32.7152
16   -4.3525007  1.737247 14.16278 26.5883  32.6781
17   -3.5579640  2.427497 14.64024 26.8530  32.8385
18   -2.7821201  3.104937 15.11690 27.1289  33.0159
19   -1.9790693  3.800369 15.59275 27.3851  33.1646
20   -1.2507247  4.445431 16.06788 27.6903  33.3865
21   -0.6706167  4.992698 16.54814 28.1036  33.7669
22   -0.0321786  5.581929 17.03697 28.4920  34.1061
23    0.7878208  6.295824 17.53436 28.7729  34.2809
24    1.7680338  7.120056 18.04033 28.9606  34.3126
25    2.7272662  7.933027 18.55487 29.1767  34.3825
26    3.5589282  8.663206 19.07798 29.4928  34.5970
27    4.4415126  9.430376 19.60966 29.7890  34.7778
28    5.4482980 10.283717 20.14992 30.0161  34.8515
29    6.4928117 11.165196 20.69874 30.2323  34.9047
30    7.3396986 11.916867 21.25613 30.5954  35.1726
31    8.0441586 12.575775 21.82210 31.0684  35.6000
32    8.8220660 13.286792 22.39663 31.5065  35.9712
33    9.7293382 14.087444 22.97973 31.8720  36.2301
34   10.6439776 14.895860 23.57141 32.2470  36.4988
35   11.3712676 15.581364 24.17165 32.7619  36.9720
36   12.0903660 16.264191 24.78047 33.2968  37.4706
37   12.9621618 17.052310 25.39786 33.7434  37.8336
38   13.9690548 17.933912 26.02382 34.1137  38.0786
39   14.8961150 18.764757 26.65834 34.5519  38.4206
40   15.5880299 19.440617 27.30144 35.1623  39.0149
41   16.2838155 20.121892 27.95311 35.7843  39.6224
42   17.1058166 20.890689 28.61335 36.3360  40.1209
43   17.9817714 21.698514 29.28216 36.8658  40.5826
44   18.6610233 22.377150 29.95954 37.5419  41.2581
45   19.1808813 22.951637 30.64550 38.3394  42.1101
46   19.7841459 23.584917 31.34002 39.0951  42.8959
47   20.5213873 24.310926 32.04311 39.7753  43.5648
48   21.2465778 25.031668 32.75477 40.4779  44.2630
49   21.7264172 25.590574 33.47501 41.3594  45.2236
50   22.1476742 26.112985 34.20381 42.2946  46.2600
51   22.6982036 26.724968 34.94119 43.1574  47.1842
52   23.3692423 27.420644 35.68713 43.9536  48.0050
53   23.9709413 28.072605 36.44165 44.8107  48.9124
54   24.3957772 28.608693 37.20474 45.8008  50.0137
55   24.9012324 29.201704 37.97639 46.7511  51.0516
56   25.6136292 29.936410 38.75662 47.5768  51.8996
57   26.4819493 30.778576 39.54542 48.3123  52.6089
58   27.2901515 31.583215 40.34279 49.1024  53.3954
59   28.0053951 32.328289 41.14873 49.9692  54.2921
60   28.8530207 33.165023 41.96324 50.7615  55.0735
61   29.9067993 34.142924 42.78632 51.4297  55.6658
62   31.0646746 35.193503 43.61797 52.0424  56.1713
63   32.0654071 36.141443 44.45820 52.7749  56.8510
64   32.9512818 37.015121 45.30699 53.5989  57.6627
65   33.9291102 37.953328 46.16435 54.3754  58.3996
66   35.0297017 38.976740 47.03029 55.0838  59.0309
67   36.0927814 39.977797 47.90479 55.8318  59.7168
68   36.9113073 40.817553 48.78787 56.7582  60.6644
69   37.7036248 41.642540 49.67951 57.7165  61.6554
70   38.6422928 42.568561 50.57973 58.5909  62.5172
71   39.7057083 43.581119 51.48852 59.3959  63.2713
72   40.6774154 44.534950 52.40587 60.2768  64.1343
73   41.4311354 45.345310 53.33180 61.3183  65.2325
74   42.1677718 46.147024 54.26630 62.3856  66.3648
75   42.9301723 46.968847 55.20937 63.4499  67.4886
76   43.5601364 47.704612 56.16101 64.6174  68.7619
77   43.7706750 48.161720 57.12122 66.0807  70.4718
78   43.6707129 48.413272 58.09000 67.7667  72.5093
79   43.5686662 48.666244 59.06735 69.4685  74.5660
80   43.6408522 49.038961 60.05327 71.0676  76.4657
81   43.9707369 49.587438 61.04777 72.5081  78.1248
82   44.5808788 50.326813 62.05083 73.7748  79.5208
83   45.4473581 51.241035 63.06246 74.8839  80.6776
84   46.5017521 52.284184 64.08267 75.8812  81.6636
85   47.6254964 53.376692 65.11144 76.8462  82.5974
86   48.6454643 54.402376 66.14879 77.8952  83.6521
87   49.6079288 55.392288 67.19471 78.9971  84.7815
88   50.7825571 56.527401 68.24919 79.9710  85.7158
89   52.2754967 57.878951 69.31225 80.7456  86.3490
90   54.0486439 59.421366 70.38388 81.3464  86.7191
91   55.8745252 61.001989 71.46408 81.9262  87.0536
92   57.4111269 62.391297 72.55285 82.7144  87.6946
93   58.7265102 63.634965 73.65019 83.6654  88.5739
94   59.8812030 64.773613 74.75610 84.7386  89.6310
95   60.8442106 65.786441 75.87058 85.9547  90.8969
96   61.4961859 66.593355 76.99363 87.3939  92.4911
97   61.6555082 67.072471 78.12525 89.1780  94.5950
98   61.1305173 67.095165 79.26545 91.4357  97.4004
99   59.7777137 66.565137 80.41421 94.2633 101.0507
100  57.5292654 65.436863 81.57154 97.7062 105.6138
knots :
 [1]  3.99998  7.00000  8.00000  9.00000 10.00000 11.00000 12.00000 13.00000
 [9] 14.00000 15.00000 16.00000 17.00000 18.00000 19.00000 20.00000 22.00000
[17] 23.00000 25.00002
coef  :
 [1]  6.862887 10.368778 14.880952 17.119048 19.547619 22.166667 24.976190
 [8] 27.976190 31.166667 34.547619 38.119048 41.880952 45.833333 49.976190
[15] 54.309524 61.095238 68.452381 76.095292 81.571544  0.190476
> 1 - sum(co2 $ resid ^2) / sum((dist - mean(dist))^2)# R^2= 67.4%
[1] 0.652418
> 
> co3 <- cobs(speed, dist, "convex", lambda = -1)# 3 warnings

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.
WARNING: Some lambdas had problems in rq.fit.sfnc():
         lambda icyc ifl fidel sum|res|_s  k
[1,] 0.00547257   15  18 263.5          4 18
[2,] 0.30774511   12  18 263.5          4 18

 WARNING!  Since the optimal lambda chosen by SIC 
   corresponds to the roughest possible fit, you should
   plot() the returned object (which plots 'sic' against 'lambda')
   and possibly consider doing one of the following:
   (1) reduce 'lambda.lo', increase 'lambda.hi', increase 'lambda.length' or all of the above;
   (2) modify the number of knots.

Warning message:
In cobs(speed, dist, "convex", lambda = -1) : Check 'ifl'
> summaryCobs(co3)
List of 24
 $ call         : language cobs(x = speed, y = dist, constraint = "convex", lambda = -1)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "convex"
 $ ic           : NULL
 $ pointwise    : NULL
 $ select.knots : logi TRUE
 $ select.lambda: logi TRUE
 $ x            : num [1:50] 4 4 7 7 8 9 10 10 10 11 ...
 $ y            : num [1:50] 2 10 4 22 16 10 18 26 34 17 ...
 $ resid        : num [1:50] -5.79 2.21 -9.81 8.19 0 ...
 $ fitted       : num [1:50] 7.8 7.8 13.8 13.8 16 ...
 $ coef         : num [1:20] 7.8 10.6 14.9 17.1 19.5 ...
 $ knots        : num [1:18] 4 7 8 9 10 ...
 $ k0           : int [1:25] 18 18 18 18 18 18 18 18 15 16 ...
 $ k            : int 3
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 32539
 $ lambda       : Named num 66.3
  ..- attr(*, "names")= chr "lambda"
 $ icyc         : int [1:25] 15 15 16 13 13 12 12 12 14 15 ...
 $ ifl          : int [1:25] 1 18 1 1 1 1 1 18 1 1 ...
 $ pp.lambda    : num [1:25] 0 0.01 0.01 0.02 0.04 0.08 0.16 0.31 0.6 1.18 ...
 $ pp.sic       : num [1:25] 2.37 2.37 2.37 2.37 2.37 ...
 $ i.mask       : logi [1:25] TRUE TRUE TRUE TRUE TRUE TRUE ...
         cb.lo     ci.lo      fit    ci.up    cb.up
1   -18.188896 -9.642853  7.79451  25.2319  33.7779
2   -15.716184 -7.852488  8.19261  24.2377  32.1014
3   -14.435228 -6.860545  8.59486  24.0503  31.6249
4   -14.065626 -6.478846  9.00124  24.4813  32.0681
5   -14.252180 -6.469021  9.41175  25.2925  33.0757
6   -14.667262 -6.611198  9.82641  26.2640  34.3201
7   -15.060722 -6.737504 10.24521  27.2279  35.5511
8   -15.261611 -6.733215 10.66814  28.0695  36.5979
9   -15.161809 -6.525773 11.09521  28.7162  37.3522
10  -14.699858 -6.073933 11.52642  29.1268  37.7527
11  -13.850768 -5.360923 11.96177  29.2845  37.7743
12  -12.622720 -4.392236 12.40126  29.1948  37.4252
13  -11.061185 -3.198385 12.84489  28.8882  36.7510
14   -9.262158 -1.843794 13.29265  28.4291  35.8475
15   -7.397170 -0.443575 13.74455  27.9327  34.8863
16   -5.782277  0.790185 14.20065  27.6111  34.1836
17   -4.506533  1.797751 14.66102  27.5243  33.8286
18   -3.408972  2.687147 15.12568  27.5642  33.6603
19   -2.418466  3.506106 15.59462  27.6831  33.6077
20   -1.580704  4.223984 16.06788  27.9118  33.7165
21   -0.921072  4.824618 16.54814  28.2717  34.0173
22   -0.247350  5.437528 17.03697  28.6364  34.3213
23    0.560677  6.143388 17.53436  28.9253  34.5081
24    1.501406  6.941123 18.04033  29.1395  34.5793
25    2.438439  7.739196 18.55487  29.3706  34.6713
26    3.279139  8.475440 19.07798  29.6805  34.8768
27    4.167235  9.246310 19.60966  29.9730  35.0521
28    5.163885 10.092849 20.14992  30.2070  35.1359
29    6.201031 10.969383 20.69874  30.4281  35.1964
30    7.085760 11.746450 21.25613  30.7658  35.4265
31    7.849515 12.445151 21.82210  31.1990  35.7947
32    8.666999 13.182728 22.39663  31.6105  36.1263
33    9.586054 13.991287 22.97973  31.9682  36.3734
34   10.510397 14.806214 23.57141  32.3366  36.6324
35   11.279572 15.519828 24.17165  32.8235  37.0637
36   12.035693 16.227499 24.78047  33.3334  37.5252
37   12.912159 17.018754 25.39786  33.7770  37.8836
38   13.896917 17.885501 26.02382  34.1621  38.1507
39   14.816824 18.711546 26.65834  34.6051  38.4999
40   15.541399 19.409323 27.30144  35.1936  39.0615
41   16.262211 20.107394 27.95311  35.7988  39.6440
42   17.079027 20.872711 28.61335  36.3540  40.1477
43   17.933019 21.665796 29.28216  36.8985  40.6313
44   18.620298 22.349820 29.95954  37.5693  41.2988
45   19.169812 22.944208 30.64550  38.3468  42.1212
46   19.779172 23.581579 31.34002  39.0985  42.9009
47   20.490014 24.289872 32.04311  39.7963  43.5962
48   21.183490 24.989330 32.75477  40.5202  44.3261
49   21.672603 25.554459 33.47501  41.3956  45.2774
50   22.112296 26.089242 34.20381  42.3184  46.2953
51   22.656042 26.696674 34.94119  43.1857  47.2263
52   23.297520 27.372512 35.68713  44.0018  48.0767
53   23.883744 28.014088 36.44165  44.8692  48.9996
54   24.333295 28.566762 37.20474  45.8427  50.0762
55   24.857974 29.172673 37.97639  46.7801  51.0948
56   25.561042 29.901119 38.75662  47.6121  51.9522
57   26.401263 30.724427 39.54542  48.3664  52.6896
58   27.203642 31.525159 40.34279  49.1604  53.4819
59   27.941406 32.285346 41.14873  50.0121  54.3561
60   28.796171 33.126871 41.96324  50.7996  55.1303
61   29.826683 34.089159 42.78632  51.4835  55.7460
62   30.948462 35.115513 43.61797  52.1204  56.2875
63   31.947912 36.062593 44.45820  52.8538  56.9685
64   32.855747 36.951009 45.30699  53.6630  57.7582
65   33.838848 37.892754 46.16435  54.4360  58.4899
66   34.922331 38.904684 47.03029  55.1559  59.1382
67   35.976908 39.900035 47.90479  55.9095  59.8327
68   36.837596 40.768086 48.78787  56.8076  60.7381
69   37.681155 41.627461 49.67951  57.7316  61.6779
70   38.644794 42.570240 50.57973  58.5892  62.5147
71   39.705763 43.581156 51.48852  59.3959  63.2713
72   40.678958 44.535985 52.40587  60.2758  64.1328
73   41.445084 45.354671 53.33180  61.3089  65.2185
74   42.145882 46.132334 54.26630  62.4003  66.3867
75   42.793009 46.876798 55.20937  63.5419  67.6257
76   43.236599 47.487487 56.16101  64.8345  69.0854
77   43.253419 47.814592 57.12122  66.4278  70.9890
78   43.029423 47.982905 58.09000  68.1971  73.1506
79   42.854469 48.186949 59.06735  69.9478  75.2802
80   42.885261 48.531887 60.05327  71.5747  77.2213
81   43.195018 49.066856 61.04777  73.0287  78.9005
82   43.803006 49.804786 62.05083  74.2969  80.2987
83   44.687239 50.730921 63.06246  75.3940  81.4377
84   45.785830 51.803731 64.08267  76.3616  82.3795
85   46.990994 52.950880 65.11144  77.2720  83.2319
86   48.141987 54.064494 66.14879  78.2331  84.1556
87   49.230317 55.138874 67.19471  79.2505  85.1591
88   50.458163 56.309702 68.24919  80.1887  86.0402
89   51.911812 57.634884 69.31225  80.9896  86.7127
90   53.554788 59.089941 70.38388  81.6778  87.2130
91   55.207203 60.554152 71.46408  82.3740  87.7210
92   56.705814 61.917964 72.55285  83.1877  88.3999
93   58.126881 63.232556 73.65019  84.0678  89.1735
94   59.464570 64.494013 74.75610  85.0182  90.0476
95   60.583736 65.611638 75.87058  86.1295  91.1574
96   61.229633 66.414472 76.99363  87.5728  92.7576
97   61.089584 66.692681 78.12525  89.5578  95.1609
98   59.907545 66.274433 79.26545  92.2565  98.6233
99   57.568406 65.082479 80.41421  95.7459 103.2600
100  54.081906 63.123354 81.57154 100.0197 109.0612
knots :
 [1]  3.99998  7.00000  8.00000  9.00000 10.00000 11.00000 12.00000 13.00000
 [9] 14.00000 15.00000 16.00000 17.00000 18.00000 19.00000 20.00000 22.00000
[17] 23.00000 25.00002
coef  :
 [1]  7.794511 10.595050 14.880952 17.119048 19.547619 22.166667 24.976190
 [8] 27.976190 31.166667 34.547619 38.119048 41.880952 45.833333 49.976190
[15] 54.309524 61.095238 68.452381 76.095292 81.571544  0.190476
> 1 - sum(co3 $ resid ^2) / sum((dist - mean(dist))^2) # R^2 = 66.25%
[1] 0.65226
> 
> with(co2, plot(pp.sic ~ pp.lambda, type = "b", col = 3, log = "x"))
> with(co3, plot(pp.sic ~ pp.lambda, type = "b", col = 4, log = "x"))
> 
> plot(speed, dist, main = "cobs(speed,dist, ..) for data(cars)")
> lines(speed, fitted(co2),   col=3); rug(knots(co2),   col=3)
> lines(speed, fitted(co3),   col=4); rug(knots(co3),   col=4)
> lines(speed, fitted(co1.1), col=2); rug(knots(co1.1), col=2)
> detach(cars)
> 
> ##-- another larger example using "random" x
> set.seed(101)
> x <- round(sort(rnorm(500)), 3) # rounding -> multiple values
> sum(duplicated(x)) # 32
[1] 35
> y <- (fx <- exp(-x)) + rt(500,4)/4
> summaryCobs(cxy  <- cobs(x,y, "decrease"))
qbsks2():
 Performing general knot selection ...

 Deleting unnecessary knots ...
List of 24
 $ call         : language cobs(x = x, y = y, constraint = "decrease")
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "decrease"
 $ ic           : chr "AIC"
 $ pointwise    : NULL
 $ select.knots : logi TRUE
 $ select.lambda: logi FALSE
 $ x            : num [1:500] -3.18 -2.82 -2.47 -2.32 -2.18 ...
 $ y            : num [1:500] 23.47 17.31 11.75 10.03 8.83 ...
 $ resid        : num [1:500] 3.338 1.739 0.104 -0.198 -0.189 ...
 $ fitted       : num [1:500] 20.13 15.57 11.65 10.23 9.02 ...
 $ coef         : num [1:6] 20.133 4.399 1.931 0.852 0.123 ...
 $ knots        : num [1:5] -3.177 -0.901 -0.329 0.217 2.587
 $ k0           : num 6
 $ k            : num 6
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 2297
 $ lambda       : num 0
 $ icyc         : int 20
 $ ifl          : int 1
 $ pp.lambda    : NULL
 $ pp.sic       : NULL
 $ i.mask       : NULL
         cb.lo       ci.lo        fit     ci.up     cb.up
1   19.4261539 19.77609785 20.1332535 20.490409 20.840353
2   18.6726860 19.00159764 19.3372876 19.672978 20.001889
3   17.9355059 18.24423770 18.5593319 18.874426 19.183158
4   17.2145986 17.50401040 17.7993864 18.094762 18.384174
5   16.5099479 16.78090751 17.0574512 17.333995 17.604954
6   15.8215360 16.07492016 16.3335261 16.592132 16.845516
7   15.1493446 15.38603897 15.6276112 15.869184 16.105878
8   14.4933543 14.71425424 14.9397066 15.165159 15.386059
9   13.8535457 14.05955619 14.2698122 14.480068 14.686079
10  13.2299004 13.42193541 13.6179279 13.813920 14.005955
11  12.6224016 12.80138349 12.9840539 13.166724 13.345706
12  12.0310364 12.19789391 12.3681901 12.538486 12.705344
13  11.4557979 11.61146321 11.7703365 11.929210 12.084875
14  10.8966884 11.04209248 11.1904931 11.338894 11.484298
15  10.3537226 10.48978919 10.6286599 10.767531 10.903597
16   9.8269318  9.95456916 10.0848369 10.215105 10.342742
17   9.3163680  9.43645864  9.5590241  9.681590  9.801680
18   8.8221075  8.93549614  9.0512215  9.166947  9.280336
19   8.3442530  8.45173361  8.5614292  8.671125  8.778605
20   7.8829348  7.98523676  8.0896470  8.194057  8.296359
21   7.4383082  7.53608415  7.6358751  7.735666  7.833442
22   7.0105499  7.10436496  7.2001134  7.295862  7.389677
23   6.5998510  6.69017570  6.7823618  6.874548  6.964873
24   6.2064091  6.29361624  6.3826205  6.471625  6.558832
25   5.8304201  5.91478545  6.0008894  6.086993  6.171359
26   5.4720696  5.55377713  5.6371685  5.720560  5.802267
27   5.1315260  5.21067635  5.2914578  5.372239  5.451390
28   4.8089343  4.88555627  4.9637573  5.041958  5.118580
29   4.5044102  4.57847544  4.6540670  4.729659  4.803724
30   4.2180355  4.28947509  4.3623870  4.435299  4.506738
31   3.9498516  4.01857620  4.0887171  4.158858  4.227583
32   3.6998525  3.76577568  3.8330574  3.900339  3.966262
33   3.4679740  3.53104114  3.5954080  3.659775  3.722842
34   3.2540798  3.31430374  3.3757688  3.437234  3.497458
35   3.0579437  3.11544919  3.1741397  3.232830  3.290336
36   2.8792298  2.93430782  2.9905209  3.046734  3.101812
37   2.7174793  2.77064796  2.8249123  2.879177  2.932345
38   2.5721207  2.62418085  2.6773139  2.730447  2.782507
39   2.4425238  2.49458826  2.5477257  2.600863  2.652928
40   2.3281087  2.38157725  2.4361477  2.490718  2.544187
41   2.2217481  2.27763180  2.3346671  2.391702  2.447586
42   2.1147630  2.17283231  2.2320983  2.291364  2.349434
43   2.0081703  2.06765255  2.1283606  2.189069  2.248551
44   1.9025658  1.96239353  2.0234542  2.084515  2.144343
45   1.7981929  1.85717812  1.9173789  1.977580  2.036565
46   1.6949971  1.75197884  1.8101348  1.868291  1.925273
47   1.5925922  1.64660058  1.7017220  1.756843  1.810852
48   1.4901187  1.54060923  1.5921403  1.643671  1.694162
49   1.3859782  1.43319747  1.4813898  1.529582  1.576801
50   1.2775940  1.32308124  1.3695059  1.415931  1.461418
51   1.1685486  1.21493954  1.2622865  1.309633  1.356024
52   1.0651401  1.11404012  1.1639478  1.213856  1.262756
53   0.9699195  1.02167151  1.0744900  1.127309  1.179061
54   0.8845413  0.93866941  0.9939130  1.049157  1.103285
55   0.8099473  0.86550951  0.9222168  0.978924  1.034486
56   0.7466077  0.80242934  0.8594013  0.916373  0.972195
57   0.6946637  0.74950019  0.8054667  0.861433  0.916270
58   0.6539655  0.70664640  0.7604129  0.814179  0.866860
59   0.6240094  0.67361353  0.7242399  0.774866  0.824470
60   0.6010731  0.64749825  0.6948801  0.742262  0.788687
61   0.5768335  0.62119253  0.6664657  0.711739  0.756098
62   0.5510070  0.59437589  0.6386386  0.682901  0.726270
63   0.5239391  0.56722289  0.6113987  0.655575  0.698858
64   0.4960558  0.53994871  0.5847461  0.629544  0.673436
65   0.4677904  0.51277214  0.5586809  0.604590  0.649571
66   0.4395281  0.48588777  0.5332028  0.580518  0.626878
67   0.4115797  0.45945260  0.5083121  0.557172  0.605045
68   0.3841775  0.43358397  0.4840087  0.534433  0.583840
69   0.3574825  0.40836321  0.4602925  0.512222  0.563103
70   0.3315950  0.38384096  0.4371636  0.490486  0.542732
71   0.3065642  0.36004204  0.4146220  0.469202  0.522680
72   0.2823954  0.33696919  0.3926677  0.448366  0.502940
73   0.2590553  0.31460556  0.3713006  0.427996  0.483546
74   0.2364749  0.29291629  0.3505209  0.408125  0.464567
75   0.2145513  0.27184943  0.3303284  0.388807  0.446105
76   0.1931496  0.25133684  0.3107232  0.370110  0.428297
77   0.1721053  0.23129540  0.2917053  0.352115  0.411305
78   0.1512286  0.21162924  0.2732746  0.334920  0.395321
79   0.1303116  0.19223336  0.2554313  0.318629  0.380551
80   0.1091385  0.17299880  0.2381752  0.303352  0.367212
81   0.0874987  0.15381915  0.2215064  0.289194  0.355514
82   0.0652000  0.13459734  0.2054248  0.276252  0.345650
83   0.0420805  0.11525159  0.1899306  0.264610  0.337781
84   0.0180160  0.09571916  0.1750236  0.254328  0.332031
85  -0.0070777  0.07595753  0.1607040  0.245450  0.328486
86  -0.0332478  0.05594285  0.1469716  0.238000  0.327191
87  -0.0605107  0.03566683  0.1338264  0.231986  0.328164
88  -0.0888601  0.01513272  0.1212686  0.227404  0.331397
89  -0.1182740 -0.00564846  0.1092981  0.224245  0.336870
90  -0.1487217 -0.02666117  0.0979148  0.222491  0.344551
91  -0.1801682 -0.04788776  0.0871188  0.222125  0.354406
92  -0.2125779 -0.06931016  0.0769101  0.223130  0.366398
93  -0.2459160 -0.09091089  0.0672886  0.225488  0.380493
94  -0.2801505 -0.11267371  0.0582545  0.229183  0.396659
95  -0.3152520 -0.13458383  0.0498076  0.234199  0.414867
96  -0.3511944 -0.15662804  0.0419480  0.240524  0.435090
97  -0.3879545 -0.17879463  0.0346757  0.248146  0.457306
98  -0.4255120 -0.20107332  0.0279907  0.257055  0.481493
99  -0.4638490 -0.22345510  0.0218929  0.267241  0.507635
100 -0.5029500 -0.24593211  0.0163824  0.278697  0.535715
knots :
[1] -3.17701 -0.90100 -0.32900  0.21700  2.58701
coef  :
[1] 20.1332552  4.3994420  1.9310722  0.8518522  0.1225609  0.0163824
> 1 - sum(cxy $ resid ^ 2) / sum((y - mean(y))^2) # R^2 = 95.9%
[1] 0.94966
> 
> ## Interpolation
> if(FALSE) { ##-- since it takes too long here!
+    cpuTime(cxyI  <- cobs(x,y, "decrease", knots = unique(x)))
+    ## takes very long : 1864.46 sec. (Pent. III, 700 MHz)
+    summaryCobs(cxyI)# only 8 knots remaining!
+ }
> 
> dx <- diff(range(ux <- unique(x)))
> rx <- range(xx <- seq(ux[1] - dx/20, ux[length(ux)] + dx/20, len = 201))
> cpuTime(cxyI  <- cobs(x,y, "decrease", knots = ux, nknots = length(ux)))
Time elapsed: 0.229 
Warning message:
In cobs(x, y, "decrease", knots = ux, nknots = length(ux)) :
  The number of knots can't be equal to the number of unique x for degree = 2.
'cobs' has automatically deleted the middle knot.
> ## 17.3 sec. (Pent. III, 700 MHz)
> summary(cxyI)
COBS regression spline (degree = 2) from call:
	 cobs(x = x, y = y, constraint = "decrease", knots = ux, nknots = length(ux))
{tau=0.5}-quantile;  dimensionality of fit: 465 from {465}
x$knots[1:464]: -3.17701, -2.82300, -2.46600, ... ,  2.58701
coef[1:465]: 23.4711460, 21.8076240, 12.7756454, 11.3273211,  8.8347075, ... ,  0.0163826
R^2 = 95.93% ;  empirical tau (over all): 246/500 = 0.492 (target tau= 0.5)
> pxx <- predict(cxyI, xx)
> plot(x,y, cex = 3/4, xlim = rx, ylim = range(y, pxx[,"fit"]),
+      main = "Artificial (x,y), N=500 : `interpolating' cobs()")
> lines(xx, exp(-xx), type = "l", col = "gray40")
> lines(pxx, col = "red")
> rug(cxyI$knots, col = "blue", lwd = 0.5)
> 
> ## Deg = 1
> cpuTime(cI1 <- cobs(x,y, "decrease", knots= ux, nknots= length(ux), degree = 1))
Time elapsed: 0.218 
> summary(cI1)
COBS regression spline (degree = 1) from call:
	 cobs(x = x, y = y, constraint = "decrease", knots = ux, nknots = length(ux),     degree = 1)
{tau=0.5}-quantile;  dimensionality of fit: 465 from {465}
x$knots[1:465]: -3.17701, -2.82300, -2.46600, ... ,  2.58701
coef[1:465]: 23.4711921, 17.3106528, 11.7497490, 10.0279800,  8.8347075, ... ,  0.0163826
R^2 = 96.02% ;  empirical tau (over all): 249/500 = 0.498 (target tau= 0.5)
> pxx <- predict(cI1, xx)
> plot(x,y, cex = 3/4, xlim = rx, ylim = range(y, pxx[,"fit"]),
+      main = paste("Artificial, N=500, `interpolate'", deparse(cI1$call)))
> lines(xx, exp(-xx), type = "l", col = "gray40")
> lines(pxx, col = "red")
> rug(cI1$knots, col = "blue", lwd = 0.5)
> 
> 
> cpuTime(cxyS <- cobs(x,y, "decrease", lambda = -1))

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.

   The algorithm has converged.  You might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you have found the global minimum of the information criterion
   so that you can determine if you need to adjust any or all of
   'lambda.lo', 'lambda.hi' and 'lambda.length' and refit the model.

Time elapsed: 1.429 
> ## somewhat <  2 sec. (Pent. III, 700 MHz)
> pxx <- predict(cxyS, xx)
> pxx[xx > max(x) , ]# those outside to the right -- currently all = Inf !
            z fit
 [1,] 2.58988 Inf
 [2,] 2.62158 Inf
 [3,] 2.65329 Inf
 [4,] 2.68499 Inf
 [5,] 2.71669 Inf
 [6,] 2.74839 Inf
 [7,] 2.78009 Inf
 [8,] 2.81180 Inf
 [9,] 2.84350 Inf
[10,] 2.87520 Inf
> summaryCobs(cxyS)
List of 24
 $ call         : language cobs(x = x, y = y, constraint = "decrease", lambda = -1)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "decrease"
 $ ic           : NULL
 $ pointwise    : NULL
 $ select.knots : logi TRUE
 $ select.lambda: logi TRUE
 $ x            : num [1:500] -3.18 -2.82 -2.47 -2.32 -2.18 ...
 $ y            : num [1:500] 23.47 17.31 11.75 10.03 8.83 ...
 $ resid        : num [1:500] 0 0.114 -0.353 -0.338 -0.121 ...
 $ fitted       : num [1:500] 23.47 17.2 12.1 10.37 8.96 ...
 $ coef         : num [1:22] 23.47 8.84 4.31 3.15 2.58 ...
 $ knots        : num [1:20] -3.18 -1.67 -1.29 -1.05 -0.85 ...
 $ k0           : int [1:25] 21 21 21 21 21 20 20 20 18 18 ...
 $ k            : int 18
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 2297
 $ lambda       : Named num 0.0201
  ..- attr(*, "names")= chr "lambda"
 $ icyc         : int [1:25] 22 26 28 25 26 25 26 25 22 21 ...
 $ ifl          : int [1:25] 1 1 1 1 1 1 1 1 1 1 ...
 $ pp.lambda    : num [1:25] 0 0 0 0.001 0.001 0.003 0.005 0.01 0.02 0.039 ...
 $ pp.sic       : num [1:25] -1.83 -1.83 -1.83 -1.83 -1.83 ...
 $ i.mask       : logi [1:25] FALSE FALSE FALSE FALSE FALSE FALSE ...
          cb.lo       ci.lo        fit     ci.up     cb.up
1   22.60909228 23.19250811 23.4712016 23.749895 24.333311
2   21.54745196 22.09422790 22.3554188 22.616610 23.163386
3   20.51583131 21.02796613 21.2726092 21.517252 22.029387
4   19.51423415 19.99372402 20.2227728 20.451822 20.931311
5   18.54267135 18.99150511 19.2059097 19.420314 19.869148
6   17.60116304 18.02131588 18.2220198 18.422724 18.842877
7   16.68974121 17.08316669 17.2711032 17.459040 17.852465
8   15.80845257 16.17707263 16.3531597 16.529247 16.897867
9   14.95736171 15.30305459 15.4681895 15.633324 15.979017
10  14.13655412 14.46114019 14.6161926 14.771245 15.095831
11  13.34613885 13.65136470 13.7971688 13.942973 14.248199
12  12.58625050 12.87377162 13.0111184 13.148465 13.435986
13  11.85704987 12.12841294 12.2580411 12.387669 12.659032
14  11.15872306 11.41534882 11.5379371 11.660525 11.917151
15  10.49147856 10.73464665 10.8508063 10.966966 11.210134
16   9.85554231 10.08637947 10.1966487 10.306918 10.537755
17   9.25115067  9.47062370  9.5754644  9.680305  9.899778
18   8.67854175  8.88745630  8.9872533  9.087050  9.295965
19   8.13794525  8.33695154  8.4320154  8.527079  8.726086
20   7.62957132  7.81917734  7.9097507  8.000324  8.189930
21   7.15359837  7.33419138  7.4204593  7.506727  7.687320
22   6.71015959  6.88203672  6.9641412  7.046246  7.218123
23   6.29932763  6.46273684  6.5407962  6.618856  6.782265
24   5.92109619  6.07628970  6.1504245  6.224559  6.379753
25   5.57535741  5.72266045  5.7930260  5.863392  6.010695
26   5.26187464  5.40177256  5.4686008  5.535429  5.675327
27   4.97998285  5.11323149  5.1768834  5.240535  5.373784
28   4.71452019  4.84220607  4.9032007  4.964195  5.091881
29   4.45743742  4.58039190  4.6391263  4.697861  4.820815
30   4.20929180  4.32796910  4.3846604  4.441352  4.560029
31   3.97048364  4.08506709  4.1398028  4.194538  4.309122
32   3.74121251  3.85175038  3.9045535  3.957357  4.067895
33   3.52143522  3.62800502  3.6789126  3.729820  3.836390
34   3.31215059  3.41508255  3.4642524  3.513422  3.616354
35   3.11804329  3.21779561  3.2654466  3.313097  3.412850
36   2.93992965  3.03669890  3.0829249  3.129151  3.225920
37   2.77795791  2.87184036  2.9166873  2.961534  3.055417
38   2.63015751  2.72137746  2.7649526  2.808528  2.899748
39   2.48502157  2.57389621  2.6163510  2.658806  2.747680
40   2.34085199  2.42748522  2.4688693  2.510253  2.596887
41   2.19769497  2.28216392  2.3225141  2.362864  2.447333
42   2.06197167  2.14454569  2.1839907  2.223436  2.306010
43   1.93967240  2.02056431  2.0592058  2.097847  2.178739
44   1.82957434  1.90899881  1.9469393  1.984880  2.064304
45   1.72067396  1.79881711  1.8361455  1.873474  1.951617
46   1.61056369  1.68745240  1.7241816  1.760911  1.837799
47   1.50359280  1.57934731  1.6155347  1.651722  1.727477
48   1.41671095  1.49151568  1.5272493  1.562983  1.637788
49   1.34837864  1.42240255  1.4577632  1.493124  1.567148
50   1.26127331  1.33474586  1.3698432  1.404940  1.478413
51   1.14711659  1.22023500  1.2551631  1.290091  1.363210
52   1.05313018  1.12612202  1.1609897  1.195857  1.268849
53   0.99745150  1.07049149  1.1053822  1.140273  1.213313
54   0.93193770  1.00523865  1.0402540  1.075269  1.148570
55   0.82700232  0.90069620  0.9358992  0.971102  1.044796
56   0.71302300  0.78723111  0.8226798  0.858128  0.932337
57   0.63795062  0.71250560  0.7481200  0.783734  0.858289
58   0.60243694  0.67711402  0.7127867  0.748459  0.823136
59   0.59829198  0.67311668  0.7088599  0.744603  0.819428
60   0.59282968  0.66813189  0.7041032  0.740075  0.815377
61   0.58400039  0.66006551  0.6964013  0.732737  0.808802
62   0.57495107  0.65177996  0.6884806  0.725181  0.802010
63   0.56577469  0.64335477  0.6804142  0.717474  0.795054
64   0.54107373  0.61966540  0.6572081  0.694751  0.773342
65   0.47693041  0.55694100  0.5951615  0.633382  0.713393
66   0.40412123  0.48578868  0.5248006  0.563813  0.645480
67   0.34798082  0.43125051  0.4710278  0.510805  0.594075
68   0.30845654  0.39330948  0.4338431  0.474377  0.559230
69   0.28333865  0.36998945  0.4113819  0.452774  0.539425
70   0.26510813  0.35372976  0.3960637  0.438398  0.527019
71   0.25307874  0.34376203  0.3870808  0.430400  0.521083
72   0.24696961  0.33996321  0.3843856  0.428808  0.521802
73   0.23851080  0.33415227  0.3798395  0.425527  0.521168
74   0.22205880  0.32047227  0.3674837  0.414495  0.512909
75   0.19762838  0.29892798  0.3473181  0.395708  0.497008
76   0.16493198  0.26942647  0.3193427  0.369259  0.473753
77   0.12615653  0.23443077  0.2861526  0.337874  0.446149
78   0.09047648  0.20293716  0.2566588  0.310380  0.422841
79   0.05885765  0.17576339  0.2316084  0.287453  0.404359
80   0.03122539  0.15288532  0.2110014  0.269117  0.390777
81   0.00727521  0.13420453  0.1948377  0.255471  0.382400
82  -0.01347494  0.11956518  0.1831175  0.246670  0.379710
83  -0.03271934  0.10753366  0.1745315  0.241529  0.381782
84  -0.05312493  0.09515173  0.1659824  0.236813  0.385090
85  -0.07450384  0.08239138  0.1573391  0.232287  0.389182
86  -0.09673967  0.06929025  0.1486015  0.227913  0.393943
87  -0.11986569  0.05583758  0.1397697  0.223702  0.399405
88  -0.14402704  0.04198646  0.1308437  0.219701  0.405715
89  -0.16944869  0.02766415  0.1218235  0.215983  0.413096
90  -0.19640782  0.01278106  0.1127090  0.212637  0.421826
91  -0.22520954 -0.00276145  0.1035004  0.209762  0.432210
92  -0.25616579 -0.01906423  0.0941974  0.207459  0.444561
93  -0.28957765 -0.03622459  0.0848003  0.205825  0.459178
94  -0.32572171 -0.05433196  0.0753089  0.204950  0.476340
95  -0.36484093 -0.07346487  0.0657233  0.204912  0.496288
96  -0.40713991 -0.09368946  0.0560435  0.205776  0.519227
97  -0.45278411 -0.11505923  0.0462695  0.207598  0.545323
98  -0.50190202 -0.13761570  0.0364012  0.210418  0.574704
99  -0.55458927 -0.16138981  0.0264387  0.214267  0.607467
100 -0.61091376 -0.18640349  0.0163820  0.219167  0.643678
knots :
 [1] -3.17701 -1.67200 -1.29300 -1.05100 -0.85000 -0.69700 -0.53500 -0.40300
 [9] -0.28100 -0.15700 -0.02600  0.16500  0.26900  0.44000  0.54600  0.74700
[17]  0.95200  1.21000  1.55300  2.58701
coef  :
 [1] 23.4712039  8.8370254  4.3078426  3.1485055  2.5789729  2.1356146
 [7]  1.8387645  1.5534839  1.4158987  1.1540057  1.0654814  0.7096368
[13]  0.7096368  0.6913826  0.6719781  0.4621872  0.3844119  0.3844119
[19]  0.2057951  0.1061021  0.0163819 11.5718036
> R2 <- 1 - sum(cxyS $ resid ^ 2) / sum((y - mean(y))^2)
> R2 # R^2 = 96.3%, now 96.83%
[1] 0.956557
> 
> plot(x,y, cex = 3/4, xlim = rx, ylim = range(y, pxx[,"fit"], finite = TRUE),
+      main = "Artificial (x,y), N=500 : cobs(*, lambda = -1)")
> mtext(substitute(R^2 == r2 * "%", list(r2 = round(100*R2,1))))
> lines(xx, exp(-xx), type = "l", col = "gray40")
> lines(pxx, col = "red")
> rug(cxyS$knots, col = "blue", lwd = 1.5)
> 
> ## Show print-monitoring :
> 
> cxyS <- cobs(x,y, "decrease", lambda = -1, print.mesg = 2)# << improve! (1 line)

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.
fieq=TRUE -> Tnobs = 559, n0 = 59, |ptConstr| = 0

   The algorithm has converged.  You might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you have found the global minimum of the information criterion
   so that you can determine if you need to adjust any or all of
   'lambda.lo', 'lambda.hi' and 'lambda.length' and refit the model.

> cxyS <- cobs(x,y, "none",     lambda = -1, print.mesg = 3)

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.
loo.design2(): ->  Xeq  501 x 22 (nz = 1501 =^=  0.14%) 
                  Xieq   38 x 22 (nz = 152 =^=  0.18%) 
........................ 

   The algorithm has converged.  You might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you have found the global minimum of the information criterion
   so that you can determine if you need to adjust any or all of
   'lambda.lo', 'lambda.hi' and 'lambda.length' and refit the model.

> 
> ## this does NOT converge (and "trace = 3" does *not* show it -- improve!)
> 
> cxyC <- cobs(x,y, "concave", lambda = -1)

 Searching for optimal lambda. This may take a while.
   While you are waiting, here is something you can consider
   to speed up the process:
       (a) Use a smaller number of knots;
       (b) Set lambda==0 to exclude the penalty term;
       (c) Use a coarser grid by reducing the argument
 	   'lambda.length' from the default value of 25.

 WARNING!  Since the optimal lambda chosen by SIC 
   rests on a flat portion, you might
   plot() the returned object (which plots 'sic' against 'lambda')
   to see if you want to reduce 'lambda.lo' and/or increase 'lambda.ho'

> summaryCobs(cxyC)
List of 24
 $ call         : language cobs(x = x, y = y, constraint = "concave", lambda = -1)
 $ tau          : num 0.5
 $ degree       : num 2
 $ constraint   : chr "concave"
 $ ic           : NULL
 $ pointwise    : NULL
 $ select.knots : logi TRUE
 $ select.lambda: logi TRUE
 $ x            : num [1:500] -3.18 -2.82 -2.47 -2.32 -2.18 ...
 $ y            : num [1:500] 23.47 17.31 11.75 10.03 8.83 ...
 $ resid        : num [1:500] 18.33 12.6 7.47 5.92 4.89 ...
 $ fitted       : num [1:500] 5.14 4.71 4.28 4.1 3.94 ...
 $ coef         : num [1:22] 5.14 4.23 3.09 2.72 2.45 ...
 $ knots        : num [1:20] -3.18 -1.67 -1.29 -1.05 -0.85 ...
 $ k0           : int [1:25] 21 21 21 21 21 21 21 21 21 21 ...
 $ k            : int 21
 $ x.ps         :Formal class 'matrix.csr' [package "SparseM"] with 4 slots
 $ SSy          : num 2297
 $ lambda       : Named num 0.295
  ..- attr(*, "names")= chr "lambda"
 $ icyc         : int [1:25] 21 20 16 19 18 21 20 20 20 20 ...
 $ ifl          : int [1:25] 1 1 1 1 1 1 1 1 1 1 ...
 $ pp.lambda    : num [1:25] 0 0 0 0.001 0.001 0.003 0.005 0.01 0.02 0.039 ...
 $ pp.sic       : num [1:25] -0.939 -0.939 -0.939 -0.939 -0.939 ...
 $ i.mask       : logi [1:25] FALSE FALSE FALSE FALSE FALSE FALSE ...
         cb.lo       ci.lo         fit      ci.up      cb.up
1    3.2540132  4.56864309  5.13970311  5.7107631  7.0253930
2    3.3078587  4.53590540  5.06935468  5.6028040  6.8308506
3    3.3554272  4.50126677  4.99900624  5.4967457  6.6425853
4    3.3966923  4.46471925  4.92865781  5.3925964  6.4606233
5    3.4316329  4.42625642  4.85830938  5.2903623  6.2849859
6    3.4602358  4.38587430  4.78796095  5.1900476  6.1156860
7    3.4825004  4.34357268  4.71761252  5.0916524  5.9527246
8    3.4984434  4.29935663  4.64726408  4.9951715  5.7960848
9    3.5081059  4.25323862  4.57691565  4.9005927  5.6457254
10   3.5115613  4.20524084  4.50656722  4.8078936  5.5015732
11   3.5089239  4.15539794  4.43621879  4.7170396  5.3635137
12   3.5003588  4.10375990  4.36587036  4.6279808  5.2313819
13   3.4860907  4.05039475  4.29552192  4.5406491  5.1049532
14   3.4664107  3.99539069  4.22517349  4.4549563  4.9839363
15   3.4416805  3.93885722  4.15482506  4.3707929  4.8679697
16   3.4123305  3.88092472  4.08447663  4.2880285  4.7566227
17   3.3788524  3.82174205  4.01412820  4.2065143  4.6494040
18   3.3417841  3.76147213  3.94377976  4.1260874  4.5457754
19   3.3016889  3.70028555  3.87343133  4.0465771  4.4451738
20   3.2591290  3.63835257  3.80308290  3.9678132  4.3470368
21   3.2146354  3.57583397  3.73273447  3.8896350  4.2508336
22   3.1686751  3.51287123  3.66238604  3.8119008  4.1560970
23   3.1216168  3.44957595  3.59203760  3.7344993  4.0624584
24   3.0736927  3.38601847  3.52168917  3.6573599  3.9696856
25   3.0249556  3.32221480  3.45134074  3.5804667  3.8777258
26   2.9752284  3.25811127  3.38099231  3.5038733  3.7867562
27   2.9240322  3.19356286  3.31064388  3.4277249  3.6972556
28   2.8703441  3.12825982  3.24029544  3.3523311  3.6102468
29   2.8145073  3.06230609  3.16994701  3.2775879  3.5253867
30   2.7573354  2.99594800  3.09959858  3.2032492  3.4418618
31   2.6994314  2.92936823  3.02925015  3.1291321  3.3590689
32   2.6411230  2.86266601  2.95890172  3.0551374  3.2766804
33   2.5823991  2.79583791  2.88855328  2.9812687  3.1947075
34   2.5227652  2.72873426  2.81820485  2.9076754  3.1136445
35   2.4619227  2.66126460  2.74785642  2.8344482  3.0337902
36   2.4004285  2.59359758  2.67750799  2.7614184  2.9545875
37   2.3385189  2.52580476  2.60715956  2.6885143  2.8758002
38   2.2759590  2.45781498  2.53681112  2.6158073  2.7976633
39   2.2125547  2.38956952  2.46646269  2.5433559  2.7203706
40   2.1487596  2.32120569  2.39611426  2.4710228  2.6434689
41   2.0846519  2.25274719  2.32576583  2.3987845  2.5668797
42   2.0198295  2.18407226  2.25541740  2.3267625  2.4910052
43   1.9543928  2.11521127  2.18506896  2.2549267  2.4157452
44   1.8883513  2.04616714  2.11472053  2.1832739  2.3410898
45   1.8217822  1.97696326  2.04437210  2.1117809  2.2669620
46   1.7550253  1.90770248  1.97402367  2.0403449  2.1930220
47   1.6878943  1.83832839  1.90367524  1.9690221  2.1194562
48   1.6202328  1.76879368  1.83332680  1.8978599  2.0464208
49   1.5520736  1.69910823  1.76297837  1.8268485  1.9738831
50   1.4832876  1.62923295  1.69262994  1.7560269  1.9019723
51   1.4139431  1.55918857  1.62228151  1.6853744  1.8306199
52   1.3439885  1.48895940  1.55193308  1.6149067  1.7598776
53   1.2735406  1.41858085  1.48158464  1.5445884  1.6896286
54   1.2025397  1.34803482  1.41123621  1.4744376  1.6199327
55   1.1311646  1.27737546  1.34088778  1.4044001  1.5506110
56   1.0594865  1.20662436  1.27053935  1.3344543  1.4815922
57   0.9881607  1.13597996  1.20019092  1.2644019  1.4122211
58   0.9173004  1.06547651  1.12984248  1.1942085  1.3423845
59   0.8463551  0.99494733  1.05949405  1.1240408  1.2726330
60   0.7745884  0.92416938  0.98914562  1.0541219  1.2037028
61   0.7021077  0.85317521  0.91879719  0.9844192  1.1354867
62   0.6295499  0.78215771  0.84844876  0.9147398  1.0673476
63   0.5569282  0.71112084  0.77810032  0.8450798  0.9992724
64   0.4836357  0.63988083  0.70775189  0.7756230  0.9318681
65   0.4093125  0.56832866  0.63740346  0.7064783  0.8654944
66   0.3343711  0.49658930  0.56705503  0.6375208  0.7997390
67   0.2594524  0.42485683  0.49670660  0.5685564  0.7339608
68   0.1844630  0.35310294  0.42635816  0.4996134  0.6682533
69   0.1089016  0.28117581  0.35600973  0.4308437  0.6031178
70   0.0328311  0.20909450  0.28566130  0.3622281  0.5384915
71  -0.0436111  0.13690066  0.21531287  0.2937251  0.4742368
72  -0.1207780  0.06448731  0.14496444  0.2254416  0.4107069
73  -0.1988521 -0.00820075  0.07461600  0.1574328  0.3480841
74  -0.2774135 -0.08103637  0.00426757  0.0895715  0.2859486
75  -0.3564848 -0.15402645 -0.06608086  0.0218647  0.2243231
76  -0.4365073 -0.22730454 -0.13642929 -0.0455540  0.1636487
77  -0.5180714 -0.30104951 -0.20677772 -0.1125059  0.1045159
78  -0.6008094 -0.37514998 -0.27712616 -0.1791023  0.0465571
79  -0.6844618 -0.44952738 -0.34747459 -0.2454218 -0.0104874
80  -0.7691796 -0.52422741 -0.41782302 -0.3114186 -0.0664664
81  -0.8554282 -0.59939103 -0.48817145 -0.3769519 -0.1209147
82  -0.9439111 -0.67523129 -0.55851988 -0.4418085 -0.1731287
83  -1.0351390 -0.75190283 -0.62886832 -0.5058338 -0.2225976
84  -1.1284587 -0.82920785 -0.69921675 -0.5692256 -0.2699748
85  -1.2235560 -0.90705119 -0.76956518 -0.6320792 -0.3155744
86  -1.3204420 -0.98543625 -0.83991361 -0.6943910 -0.3593852
87  -1.4193598 -1.06443660 -0.91026204 -0.7560875 -0.4011642
88  -1.5207178 -1.14417593 -0.98061048 -0.8170450 -0.4405031
89  -1.6250324 -1.22481061 -1.05095891 -0.8771072 -0.4768855
90  -1.7328771 -1.30651438 -1.12130734 -0.9361003 -0.5097376
91  -1.8448394 -1.38946510 -1.19165577 -0.9938464 -0.5384722
92  -1.9614844 -1.47383392 -1.26200420 -1.0501745 -0.5625240
93  -2.0833282 -1.55977716 -1.33235264 -1.1049281 -0.5813770
94  -2.2108206 -1.64743101 -1.40270107 -1.1579711 -0.5945815
95  -2.3443367 -1.73690906 -1.47304950 -1.2091899 -0.6017623
96  -2.4841766 -1.82830219 -1.54339793 -1.2584937 -0.6026193
97  -2.6305704 -1.92168011 -1.61374636 -1.3058126 -0.5969223
98  -2.7836872 -2.01709401 -1.68409480 -1.3510956 -0.5845024
99  -2.9436449 -2.11457961 -1.75444323 -1.3943068 -0.5652415
100 -3.1105208 -2.21416030 -1.82479166 -1.4354230 -0.5390625
knots :
 [1] -3.17701 -1.67200 -1.29300 -1.05100 -0.85000 -0.69700 -0.53500 -0.40300
 [9] -0.28100 -0.15700 -0.02600  0.16500  0.26900  0.44000  0.54600  0.74700
[17]  0.95200  1.21000  1.55300  2.58701
coef  :
 [1]  5.13970e+00  4.23047e+00  3.09228e+00  2.71711e+00  2.44948e+00
 [6]  2.23561e+00  2.04531e+00  1.86770e+00  1.71424e+00  1.56563e+00
[11]  1.41157e+00  1.21704e+00  1.03882e+00  8.72683e-01  7.05337e-01
[16]  5.19867e-01  2.74588e-01 -5.12686e-03 -3.68213e-01 -1.20011e+00
[21] -1.82479e+00  3.65453e-11
> 
> 
> dev.off()
null device 
          1 
> 
